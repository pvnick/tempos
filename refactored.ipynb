{
 "metadata": {
  "name": "",
  "signature": "sha256:988f0eb5a1062f6f3b7f8be2b49052f5692a32e25b2fe7bcd0e82e81209ed410"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# file=\"painSAX.py\" Instituition=\"University of Florida, Intelligent Health Lab\"\n",
      "# THIS CODE AND INFORMATION ARE PROVIDED \"AS IS\" WITHOUT WARRANTY OF ANY\n",
      "# KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n",
      "# IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A\n",
      "# PARTICULAR PURPOSE.\n",
      "\n",
      "__author__ = \"Paul Nickerson, Parisa Rashidi, Patrick Tighe\"\n",
      "__copyright__ = \"Copyright 2014, The Pain SAX Project\"\n",
      "__credits__ = [\"Eamonn Keogh group (University of California - Riverside)\"]\n",
      "__license__ = \"GPL\"\n",
      "__version__ = \"1.0.1\"\n",
      "__maintainer__ = \"Paul Nickerson\"\n",
      "__email__ = \"pvnick@ufl.edu\"\n",
      "__status__ = \"Experimental\"\n",
      "\n",
      "import subprocess\n",
      "import shutil\n",
      "import sys\n",
      "import locale\n",
      "import scipy as sc\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os\n",
      "import math\n",
      "import string\n",
      "import re\n",
      "from pylab import plt\n",
      "from matplotlib.artist import setp\n",
      "from matplotlib import gridspec, patches, transforms, ticker\n",
      "from scipy.interpolate import interp1d\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from statsmodels.stats.diagnostic import kstest_normal as lilliefors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seed = get_opt_val(\"driver.rng_seed\")\n",
      "np.random.seed(seed) #ensure we get consistent replicatable results\n",
      "plt.rcParams['mathtext.default'] = get_opt_val(\"driver.mathtext.fontstyle\")\n",
      "utils = PainDataUtils()\n",
      "utils.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'get_opt_val' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-c62d4eaf25f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_opt_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"driver.rng_seed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#ensure we get consistent replicatable results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mathtext.default'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_opt_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"driver.mathtext.fontstyle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPainDataUtils\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'get_opt_val' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opts = {\n",
      "    #the following options are general to any data set\n",
      "    \"driver.mathtext.fontstyle\": \"it\",\n",
      "    \"driver.rng_seed\": 10, #ensure we get consistent replicatable results\n",
      "    \"driver.bootstrapping.num_samples\": 1000, #number of bootstrapped normalization resampling replications\n",
      "    \"driver.bootstrapping.min_stratum_size\": 50, #strata with fewer items than this will be discarded\n",
      "    \"driver.sax.alphabet_size\": 5, #\"beta\" from the manuscript\n",
      "    \"driver.sax.paa_frame_length\": 5 * 60, #5 hours\n",
      "    \"driver.icons.icons_per_row\": 3, \n",
      "    \"driver.icons.icon_set_figure_size\": (23, 20), #(width, height) tuple\n",
      "    \"driver.icons.output_path\": os.path.join(\"/home\", \"pvnick\", \"winvirtual\", \"icons.pdf\"),\n",
      "\n",
      "    #if true, will sort displayed icons in descending cosine similarity\n",
      "    #otherwise, will sort by stratum name\n",
      "    \"driver.icons.sort_by_similarity\": True, \n",
      "\n",
      "    #if true, each icon (besides the first one) will be rendered with its similarity\n",
      "    #to the first displayed icon\n",
      "    \"driver.icons.show_icon_similarities\": True, \n",
      "\n",
      "    #id for the stratum whose icon will be displayed first, and all other\n",
      "    #icons will be shown in descending cosine similarity (only applicable\n",
      "    #when driver.icons.sort_by_similarity is True\n",
      "    \"driver.icons.first_displayed_stratum\": \"Male, age 21-39\", \n",
      "\n",
      "    #each unique value for this column is associated with its own time series in the dataset\n",
      "    \"driver.time_series.owner_id_label\": \"PatientID\", \n",
      "\n",
      "    \"driver.time_series.x_label\": \"NRSTimeFromEndSurgery_mins\", #x axis for the time series\n",
      "    \"driver.time_series.y_label\": \"PainScoreQuantMissing\", #y axis for the time series\n",
      "    \"driver.time_series.interpolation_interval\": 10, #step size for time series linear interpolation\n",
      "    #the following options are specific to the pain data set used to develop the procedure\n",
      "    \"pain_data.data_file_path\": os.path.join(\"/home\", \"pvnick\", \"winvirtual\", \"pain_encrypted.csv\"),\n",
      "    \"pain_data.output_directory\": os.path.join(\"/home\", \"pvnick\", \"winvirtual\", \"tempos\"),\n",
      "    \"pain_data.tmp_directory\": os.path.join(\"/tmp\"),\n",
      "    \"pain_data.start_recording_time_minutes_cutoff\": 120,\n",
      "    \"pain_data.table1_out_path\": \"table1.csv\",\n",
      "    \"pain_data.figures.start_times_lte_cutoff\": \"pain_score_start_times_lte_2hours.pdf\",\n",
      "    \"pain_data.figures.start_times\": \"pain_score_start_times.pdf\",\n",
      "    \"pain_data.figures.raw_scores_histogram\": \"raw_scores_histogram.pdf\",\n",
      "    \"pain_data.figures.interpolation_demo.interpolation\": \"interpolation_demo.pdf\",\n",
      "    \"pain_data.figures.interpolation_demo.paa\": \"paa_demo.pdf\",\n",
      "    \"pain_data.figures.interpolation_demo.sax\": \"sax_demo.pdf\",\n",
      "    \"pain_data.figures.paa_frame_length_demo\": \"paa_frame_length_demo.pdf\",\n",
      "}\n",
      "\n",
      "def get_opt_val(option, default = \"\"):\n",
      "    if option not in opts:\n",
      "        print \"Option '\" + option + \"' not found\"\n",
      "        raise \n",
      "    return opts[option]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Driver:\n",
      "    def __init__(self, ts_df, stratification_callback):\n",
      "        self.ts_df = ts_df\n",
      "        self.all_motifs = {}\n",
      "        self.saxes = []\n",
      "        self.ts_df_interpolated = None\n",
      "        self.owner_motif_matrices = []\n",
      "        self.icons = None\n",
      "        self.breakpoints = []\n",
      "        self.stratification_callback = stratification_callback\n",
      "    \n",
      "    def run(self):\n",
      "        print(\"Interpolating time series to fixed intervals of %d time units\" % (get_opt_val(\"driver.time_series.interpolation_interval\")))\n",
      "        self.interpolate_timeseries()\n",
      "        print(\"Calculating quantile breakpoints based on all time series\")\n",
      "        self.define_breakpoints()\n",
      "        print(\"Calculating sax words for each owned time series\")\n",
      "        self.define_sax_words()\n",
      "        print(\"Defining a motif matrix for each time series\")\n",
      "        self.define_motif_matrices()\n",
      "        print(\"Normalizing\")\n",
      "        self.normalize()\n",
      "        print(\"Calculating strata cosine similarities\")\n",
      "        self.calculate_strata_similarities()\n",
      "        print(\"Saving icon set to \" + get_opt_val(\"driver.icons.output_path\"))\n",
      "        self.save_icons()\n",
      "        \n",
      "    def define_motif_matrices(self): \n",
      "        self.owner_motif_matrices = self.saxes.apply(self.get_raw_sequence_motif_vector)\n",
      "\n",
      "    def define_breakpoints(self):\n",
      "        def owner_paa(owner_series):\n",
      "            frame_length = float(get_opt_val(\"driver.sax.paa_frame_length\"))\n",
      "            interval_minutes = float(get_opt_val(\"driver.time_series.interpolation_interval\"))\n",
      "            frame_points = frame_length / interval_minutes\n",
      "            paa_size = np.ceil(owner_series.count() / frame_points) \n",
      "            return self.piecewise_aggregate_approximation(owner_series, paa_size)\n",
      "\n",
      "        ts_y_label = get_opt_val(\"driver.time_series.y_label\")\n",
      "        ts_owner_label = get_opt_val(\"driver.time_series.owner_id_label\")\n",
      "        groupedby_owner = self.ts_df_interpolated[ts_y_label].groupby(level = ts_owner_label)\n",
      "        #get PAAs for all owned time series and concatenate them\n",
      "        all_paa = groupedby_owner.apply(owner_paa)\n",
      "        all_paa_series = pd.Series(all_paa.values)\n",
      "        #use the concatenated PAAs to generate quantile-based breakpoints that are applied to each owned time series\n",
      "        self.breakpoints = self.get_quantile_breakpoints(all_paa_series)\n",
      "    \n",
      "    def define_sax_words(self):\n",
      "        def owner_sax(owner_series, breakpoints):\n",
      "            frame_length = float(get_opt_val(\"driver.sax.paa_frame_length\"))\n",
      "            interval_minutes = float(get_opt_val(\"driver.time_series.interpolation_interval\"))\n",
      "            frame_points = frame_length / interval_minutes\n",
      "            paa_size = np.ceil(owner_series.count() / frame_points) \n",
      "            return self.sax(pd.Series(owner_series.values), paa_size, breakpoints)\n",
      "\n",
      "        ts_y_label = get_opt_val(\"driver.time_series.y_label\")\n",
      "        ts_owner_label = get_opt_val(\"driver.time_series.owner_id_label\")\n",
      "        groupedby_owner = self.ts_df_interpolated[ts_y_label].groupby(level = ts_owner_label)\n",
      "        self.saxes = groupedby_owner.apply(owner_sax, breakpoints = self.breakpoints)\n",
      "        \n",
      "\n",
      "    #The following function accepts a pandas dataframe like the following:\n",
      "    # Patient ID | Record Time | Value | Other Column(s)\n",
      "    # 1          | 1           | 4     | Val 1\n",
      "    # 1          | 75          | 9     | Val 1\n",
      "    # 1          | 100         | 7     | Val 1\n",
      "    # 2          | 8           | 1     | Val 2\n",
      "    # 2          | 19          | 6     | Val 2\n",
      "    # 2          | 50          | 3     | Val 2\n",
      "    #And returns the following:\n",
      "    # Patient ID | Record Time | Value | Other Column(s)\n",
      "    # 1          | 4           | 5.00  | Val 1\n",
      "    # 1          | 14          | 5.56  | Val 1\n",
      "    # 1          | 24          | 6.12  | Val 1\n",
      "    # ...\n",
      "    # 1          | 84          | 8.28  | Val 1\n",
      "    # 1          | 94          | 7.48  | Val 1\n",
      "    # 2          | 8           | 1.00  | Val 2\n",
      "    # ...\n",
      "    # 2          | 48          | 3.19  | Val 2\n",
      "    def interpolate_timeseries(self):\n",
      "        def interpolate_owner_ts(dataframe_multiindexed):\n",
      "            interval_minutes = get_opt_val(\"driver.time_series.interpolation_interval\")\n",
      "            #pandas automatically re-adds this in post-processing. remove it so we dont have a duplicate\n",
      "            dataframe_multiindexed.index = dataframe_multiindexed.index.droplevel(0)\n",
      "            if dataframe_multiindexed[ts_y_label].count() <= 1:\n",
      "                #interpolation requires at least two points\n",
      "                return dataframe_multiindexed\n",
      "            dataframe_multiindexed.dropna(subset=[ts_y_label], inplace=True)\n",
      "            dataframe_unindexed = dataframe_multiindexed.reset_index()\n",
      "            dataframe_time_indexed = dataframe_unindexed.set_index(ts_x_label).sort_index()\n",
      "            \n",
      "            #expand the original data structure by forward-filling feature values through the interpolated values\n",
      "            first_time_value = dataframe_unindexed[ts_x_label].iloc[0]\n",
      "            last_time_value = dataframe_unindexed[ts_x_label].iloc[-1]\n",
      "            constant_time_interval_points = np.arange(first_time_value, last_time_value, interval_minutes)\n",
      "            total_indexed_by_time = dataframe_unindexed.set_index(ts_x_label)\n",
      "            total_indexed_by_time_expanded = total_indexed_by_time.reindex(constant_time_interval_points, method='ffill')\n",
      "            \n",
      "            #use linear interpolation from scipy\n",
      "            interpolation_func = interp1d(x=dataframe_unindexed[ts_x_label], \n",
      "                                          y=dataframe_unindexed[ts_y_label])\n",
      "            interpolated_vals = interpolation_func(constant_time_interval_points)\n",
      "            total_indexed_by_time_expanded[ts_y_label] = [interpolated_val if interpolated_val > 0 else 0 for interpolated_val in interpolated_vals]\n",
      "            return total_indexed_by_time_expanded\n",
      "\n",
      "        ts_owner_label = get_opt_val(\"driver.time_series.owner_id_label\")\n",
      "        ts_x_label = get_opt_val(\"driver.time_series.x_label\")\n",
      "        ts_y_label = get_opt_val(\"driver.time_series.y_label\")\n",
      "        ts_indexed = self.ts_df.set_index([ts_owner_label, ts_x_label])\n",
      "        grouped_by_owner = ts_indexed.groupby(level=0)\n",
      "        ts_interpolated = grouped_by_owner.apply(interpolate_owner_ts)\n",
      "        ts_interpolated.dropna(subset=[ts_y_label], inplace=True)\n",
      "        \n",
      "        #dont include owners with null time series after interpolation\n",
      "        owner_ts_lengths = ts_interpolated[ts_y_label].groupby(level=0).count()\n",
      "        blank_series_owners = owner_ts_lengths[owner_ts_lengths == 0]\n",
      "        ts_interpolated.drop(blank_series_owners.index, level=0, inplace=True)\n",
      "        self.ts_df_interpolated = ts_interpolated\n",
      "    \n",
      "    def get_raw_sequence_motif_vector(self, sequence):\n",
      "        l = 2 #motif length, hardcoded for reasons outlined in paper\n",
      "        a = get_opt_val(\"driver.sax.alphabet_size\")\n",
      "        n = a ** l #possible motif combinations\n",
      "        Mp = np.zeros(n) #motif vector\n",
      "        for motif_pos in range(len(sequence) - l + 1):\n",
      "            motif = sequence[motif_pos:motif_pos + l] #current motif\n",
      "            i = 0\n",
      "            for j in np.arange(l):\n",
      "                letter = motif[j]\n",
      "                kj = string.lowercase.index(letter)\n",
      "                i += kj * a ** (l - j - 1)\n",
      "            self.all_motifs[i] = motif\n",
      "            Mp[i] += 1\n",
      "        return pd.Series(Mp)\n",
      "\n",
      "    def get_stratified_motif_matrices(self):\n",
      "        ts_owner_label = get_opt_val(\"driver.time_series.owner_id_label\")\n",
      "        #stratification_callback assumes static feature values per owner, so just get the owners associated with each stratum\n",
      "        groupedby_owner = self \\\n",
      "            .ts_df_interpolated \\\n",
      "            .reset_index() \\\n",
      "            .groupby(ts_owner_label, sort = False, as_index=False)\n",
      "        owner_features = groupedby_owner.head(1).set_index(ts_owner_label, drop = False)\n",
      "        #strata_designations is pd.Series, [{owner1: stratum_id}, {owner2: stratum_id}, etc]\n",
      "        strata_designations = owner_features.apply(self.stratification_callback, axis=1)\n",
      "        strata_joined_with_motifs_matrices = pd.concat([strata_designations.to_frame(name=\"stratum\"), \n",
      "                                                        self.owner_motif_matrices], \n",
      "                                                       axis=1)\n",
      "        #motrif_matrices_by_strata is pd.DataFrame, {stratum1: {owner1: motif_matrix1, owner2: motif_matrix2}, stratum2: etc}\n",
      "        motrif_matrices_by_strata = strata_joined_with_motifs_matrices \\\n",
      "            .reset_index() \\\n",
      "            .dropna() \\\n",
      "            .set_index([\"stratum\", ts_owner_label]) \\\n",
      "            .sort_index()\n",
      "        return motrif_matrices_by_strata\n",
      "    \n",
      "    def sample_motif_importances(self, sample_size):\n",
      "        sample_indices = np.random.choice(self.owner_motif_matrices.index, size=sample_size, replace=True)\n",
      "        sample = self.owner_motif_matrices.ix[sample_indices]\n",
      "        individual_motif_counts = sample.sum()\n",
      "        total_motif_quantities = individual_motif_counts.sum(axis=1)\n",
      "        x = individual_motif_counts / total_motif_quantities\n",
      "        return x\n",
      "    \n",
      "    def get_quantile_breakpoints(self, paa_series):\n",
      "        alphabet_size = get_opt_val(\"driver.sax.alphabet_size\")\n",
      "        i_vals = np.arange(0, alphabet_size)\n",
      "        breakpoints = [\n",
      "            paa_series.quantile(i / float(alphabet_size))\n",
      "            for i in i_vals\n",
      "        ] + [np.inf]\n",
      "        return breakpoints\n",
      "    \n",
      "    def get_cuts(self, paa_series, breakpoints):\n",
      "        cuts = paa_series.apply(lambda paa_element: np.sum(breakpoints <= paa_element))\n",
      "        return cuts\n",
      "    \n",
      "    def convert_cuts_to_sax_word(self, cuts):\n",
      "        sax_series = cuts.apply(lambda cut: string.ascii_lowercase[cut - 1])\n",
      "        sax_str = \"\".join(sax_series.values)\n",
      "        return sax_str\n",
      "    \n",
      "    def piecewise_aggregate_approximation(self, series, paa_size):\n",
      "        series = pd.Series(series.values) #disregard indices\n",
      "        paa_size = int(paa_size)\n",
      "        series_length = int(series.count())\n",
      "        #take care of the special case where there is no dimensionality reduction\n",
      "        if series_length == paa_size:\n",
      "            paa = series\n",
      "        else:\n",
      "            if series_length % paa_size == 0:\n",
      "                paa = series.reshape([series_length / paa_size, paa_size], order=\"F\").mean(axis=0)\n",
      "            else:\n",
      "                temp = pd.DataFrame(series).T.reindex(index = xrange(paa_size), method=\"ffill\")\n",
      "                expanded_sub_section = temp.values.reshape(paa_size * series_length, order=\"F\")\n",
      "                paa = expanded_sub_section.reshape([series_length, paa_size], order=\"F\").mean(axis=0)\n",
      "        return pd.Series(paa)\n",
      "    \n",
      "    def sax(self, time_series, paa_length, breakpoints):\n",
      "        paa_series = self.piecewise_aggregate_approximation(time_series, paa_length)\n",
      "        cuts = self.get_cuts(paa_series, breakpoints)\n",
      "        word = self.convert_cuts_to_sax_word(cuts)\n",
      "        return word\n",
      "    \n",
      "    def normalize(self):\n",
      "        stratified_motif_matrices = self.get_stratified_motif_matrices()\n",
      "        stratified_motif_matrices_grouped = stratified_motif_matrices.groupby(level=0)\n",
      "        strata_sample_sizes = stratified_motif_matrices_grouped.count()\n",
      "        individual_motif_counts_by_stratum = stratified_motif_matrices_grouped.sum()\n",
      "        total_motif_quantities_by_stratum = individual_motif_counts_by_stratum.sum(axis=1)\n",
      "        motif_proportions_strata = individual_motif_counts_by_stratum.apply(lambda val: val / total_motif_quantities_by_stratum)\n",
      "        stratification_criteria = motif_proportions_strata.index\n",
      "        icons = pd.DataFrame(columns = self.owner_motif_matrices.columns, index = pd.Index(data=[], name=\"stratum_id\"))\n",
      "        for criterion in stratification_criteria:\n",
      "            motif_proportions_stratum = motif_proportions_strata.ix[criterion]\n",
      "            stratum_size = strata_sample_sizes.ix[criterion][0]\n",
      "            min_stratum_size = get_opt_val(\"driver.bootstrapping.min_stratum_size\")\n",
      "            if stratum_size < min_stratum_size:\n",
      "                print(\"Skipping stratum '%s' (size=%d which is less than the minimum, %d)\" % (criterion, stratum_size, min_stratum_size))\n",
      "            else:\n",
      "                print(\"Generating Xci for stratum '%s' (size=%d)\" % (criterion, stratum_size))\n",
      "                num_samples = get_opt_val(\"driver.bootstrapping.num_samples\")\n",
      "                sample_accumulator = []\n",
      "                for i in range(num_samples):\n",
      "                    sample_accumulator.append(self.sample_motif_importances(stratum_size))\n",
      "                motif_importance_sample = pd.DataFrame(sample_accumulator)\n",
      "                numerators = motif_importance_sample.apply(lambda row: row <= motif_proportions_stratum, axis=1).sum()\n",
      "                denominators = motif_importance_sample.count()\n",
      "                CDF = numerators / denominators\n",
      "                icon = CDF\n",
      "                icons.ix[str(criterion)] = icon\n",
      "        self.icons = icons\n",
      "        \n",
      "    def calculate_strata_similarities(self):\n",
      "        def get_similarities(icon, all_icons):\n",
      "            similarities = cosine_similarity(X=icon, Y=all_icons)[0]\n",
      "            return pd.DataFrame(data=similarities, \n",
      "                                index=pd.Index(all_icons.index, name=\"other_item\"),\n",
      "                                columns=pd.Index([\"similarity\"]))\n",
      "\n",
      "        self.strata_similarities = self.icons.groupby(level=0).apply(get_similarities, all_icons=self.icons)\n",
      "        \n",
      "    def save_icons(self):\n",
      "        first_listed_stratum_id = get_opt_val(\"driver.icons.first_displayed_stratum\")\n",
      "        sort_by_similarity = get_opt_val(\"driver.icons.sort_by_similarity\")        \n",
      "        num_cols = get_opt_val(\"driver.icons.icons_per_row\")\n",
      "        figsize = get_opt_val(\"driver.icons.icon_set_figure_size\")\n",
      "        show_icon_similarities = get_opt_val(\"driver.icons.show_icon_similarities\")\n",
      "        figure_path = get_opt_val(\"driver.icons.output_path\")\n",
      "        \n",
      "        stratum_similarities = self.strata_similarities.ix[first_listed_stratum_id]\n",
      "        if sort_by_similarity:\n",
      "            strata_sorted = stratum_similarities.sort(columns=\"similarity\", ascending=False).index\n",
      "        else:\n",
      "            #sort lexicographically by stratum id\n",
      "            strata_sorted = stratum_similarities.sort_index().index\n",
      "        num_icons = float(len(self.icons.index))\n",
      "        fig, axes = plt.subplots(ncols=num_cols,\n",
      "                                 nrows=np.ceil(float(num_icons) / num_cols).astype(int), \n",
      "                                 figsize=figsize)\n",
      "        axes_flattened = axes.flatten()\n",
      "        plt.hold(True)\n",
      "        axis_index = 0\n",
      "        for stratum_id in strata_sorted:\n",
      "            ax = axes_flattened[axis_index]\n",
      "            icon = self.icons.ix[stratum_id]\n",
      "            icon_side = np.sqrt(icon.count()).astype(int)\n",
      "            #hide distracting axis ticks\n",
      "            ax.tick_params(labelbottom='off',\n",
      "                           labelleft='off')\n",
      "            ax.set_title(label=\"$\" + string.replace(stratum_id, ' ', '\\ ') + \"$\", fontsize=38, y=1.04)\n",
      "            similarity = stratum_similarities.ix[stratum_id].similarity\n",
      "            if stratum_id != first_listed_stratum_id and show_icon_similarities:\n",
      "                ax.set_xlabel(xlabel=r\"$Similarity = \" + ('%.3f' % similarity) + \"$\", \\\n",
      "                              fontsize=38, labelpad = 20)\n",
      "            else:\n",
      "                #placeholder label so icon sets can be neatly shown next to each other\n",
      "                ax.set_xlabel(xlabel=r\"a\", color=\"white\", fontsize=38, labelpad = 20)\n",
      "            pixel_data = icon.reshape([icon_side, icon_side]).astype(float)\n",
      "            heatmap = ax.pcolor(pixel_data, cmap = plt.cool())\n",
      "            ax.invert_yaxis()\n",
      "            cbar = fig.colorbar(heatmap, ax=ax)\n",
      "            cbar.ax.tick_params(labelsize=32)\n",
      "            cbar.set_ticks(np.linspace(0, 1, 5))\n",
      "            axis_index = axis_index + 1\n",
      "        for remaining_axis_index in range(axis_index, len(axes_flattened)):\n",
      "            ax = axes_flattened[remaining_axis_index]\n",
      "            fig.delaxes(ax)\n",
      "        plt.tight_layout(pad=1.6)\n",
      "        plt.savefig(figure_path, bbox_inches=\"tight\")\n",
      "        plt.close(fig)\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Stratification:\n",
      "    #owners/patients with the same stratification id will be assigned to the same stratum\n",
      "    #this class contains sample methods which are used to generate stratification ids\n",
      "    #the method used (designated during Driver initialization) takes 1 row for each timeseries owner (eg Patient)\n",
      "    #and generates a stratification id based on its feature values\n",
      "        \n",
      "    @staticmethod\n",
      "    def agegroup_gender(row):\n",
      "        #stratify by a combination of gender and age group\n",
      "        gender_feature_val = row[\"Gender\"]\n",
      "        age_group_feature_val = row[\"Age_Group\"]\n",
      "        if (gender_feature_val is None or age_group_feature_val is None):\n",
      "            #missing feature value - indicate that this row is to be discarded\n",
      "            return None\n",
      "        gender_str = \"Male\" if gender_feature_val == \"MALE\" else \"Female\"\n",
      "        ret_val = \"%s, age %s\" % (gender_str, age_group_feature_val)\n",
      "        return ret_val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class PainDataUtils:\n",
      "    def __init__(self):\n",
      "        self.output_directory = get_opt_val(\"pain_data.output_directory\")\n",
      "        self.tmp_directory = get_opt_val(\"pain_data.tmp_directory\")\n",
      "        \n",
      "    def load_data(self):\n",
      "        def get_mins_from_hhmm(hhmm):\n",
      "            parts = hhmm.split(':')\n",
      "            return int(parts[0]) * 60 + int(parts[1])\n",
      "        self.all_pain_data = pd.read_csv(get_opt_val(\"pain_data.data_file_path\"), true_values=[\"Yes\", \"True\"], false_values=[\"No\", \"False\"])\n",
      "        pain_data_columns = self.all_pain_data.columns.values\n",
      "        #rename the first column (\"id\") to something more meaningful\n",
      "        pain_data_columns[0] = \"PatientID\"\n",
      "        self.all_pain_data.columns = pain_data_columns\n",
      "        #provided timestamp is hh:mm. convert to scalar\n",
      "        self.all_pain_data[\"NRSTimeFromEndSurgery_mins\"] = self.all_pain_data.NRSTimeFromEndSurgery.apply(get_mins_from_hhmm)\n",
      "        \n",
      "    def run(self):\n",
      "        print(\"Executing routines associated with the pain score data set\")\n",
      "        self.load_data()\n",
      "        self.generate_start_time_figures()\n",
      "        self.pain_data_start_cutoff = self.generate_cutoff_start_time_figures()\n",
      "        self.normality_check()\n",
      "        print(\"Running icon driver\")\n",
      "        self.driver = Driver(self.pain_data_start_cutoff, Stratification.agegroup_gender)\n",
      "        self.driver.run()\n",
      "        print(\"Running auxillary stuff\")\n",
      "        self.gen_table1()\n",
      "        self.pain_score_histogram()\n",
      "        self.demonstrate_interpolation_procedure()\n",
      "        self.demonstrate_paa_frame_length_determination()\n",
      "        print(\"Done\")\n",
      "\n",
      "    def normality_check(self):\n",
      "        print(\"Lilliefors test for normality\")\n",
      "        #all scores\n",
      "        normality_test = lilliefors(self.pain_data_start_cutoff.PainScoreQuantMissing.dropna().values)\n",
      "        normality_test_pval = normality_test[1]\n",
      "        print(\"Null hypothesis is that all pain scores follow a Gaussian distribution\")\n",
      "        print(\"P-value for rejecting the null hypothesis = \" + str(normality_test_pval))\n",
      "        #only scores greater than 0\n",
      "        normality_test = lilliefors(self.pain_data_start_cutoff[self.pain_data_start_cutoff.PainScoreQuantMissing > 0].PainScoreQuantMissing.dropna().values)\n",
      "        normality_test_pval = normality_test[1]\n",
      "        print(\"Null hypothesis is that pain scores greater than 0 follow a Gaussian distribution\")\n",
      "        print(\"P-value for rejecting the null hypothesis = \" + str(normality_test_pval))\n",
      "    \n",
      "    #Generate histograms of patient score record start times (normal and log scale)\n",
      "    def generate_start_time_figures(self):            \n",
      "        figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.start_times\"))\n",
      "        print(\"Generating histograms for record start times and saving to \" + figure_path)\n",
      "        recording_time_grouped_by_patient = self.all_pain_data[[\"PatientID\", \"NRSTimeFromEndSurgery_mins\"]].groupby(\"PatientID\")\n",
      "        recording_start_minutes = recording_time_grouped_by_patient.min()\n",
      "\n",
      "        fig1 = \"fig1.pdf\"\n",
      "        fig2 = \"fig2.pdf\"\n",
      "\n",
      "        plt.figure(figsize=[8,4])\n",
      "        plt.title(\"Pain score recording start times\", fontsize=14).set_y(1.05) \n",
      "        plt.ylabel(\"Occurrences\", fontsize=14)\n",
      "        plt.xlabel(\"Recording Start Time (minutes)\", fontsize=14)\n",
      "        plt.hist(recording_start_minutes.values, bins=20, color=\"0.5\")\n",
      "        plt.savefig(os.path.join(self.tmp_directory, fig1), bbox_inches=\"tight\")\n",
      "        plt.close()\n",
      "\n",
      "        plt.figure(figsize=[8,4])\n",
      "        plt.title(\"Pain score recording start times, log scale\", fontsize=14).set_y(1.05) \n",
      "        plt.ylabel(\"Occurrences\", fontsize=14)\n",
      "        plt.xlabel(\"Recording Start Time (minutes)\", fontsize=14)\n",
      "        plt.hist(recording_start_minutes.values, bins=20, log=True, color=\"0.5\")\n",
      "        plt.savefig(os.path.join(self.tmp_directory, fig2), bbox_inches=\"tight\")\n",
      "        plt.close()\n",
      "\n",
      "        #save the figures in panel format\n",
      "        f = open(os.path.join(self.tmp_directory, \"tmp.tex\"), 'w')\n",
      "        f.write(r\"\"\"\n",
      "            \\documentclass[%\n",
      "            ,float=false % this is the new default and can be left away.\n",
      "            ,preview=true\n",
      "            ,class=scrartcl\n",
      "            ,fontsize=20pt\n",
      "            ]{standalone}\n",
      "            \\usepackage[active,tightpage]{preview}\n",
      "            \\usepackage{varwidth}\n",
      "            \\usepackage{graphicx}\n",
      "            \\usepackage[justification=centering]{caption}\n",
      "            \\usepackage{subcaption}\n",
      "            \\usepackage[caption=false,font=footnotesize]{subfig}\n",
      "            \\renewcommand{\\thesubfigure}{\\Alph{subfigure}}\n",
      "            \\begin{document}\n",
      "            \\begin{preview}\n",
      "            \\begin{figure}[h]\n",
      "                \\begin{subfigure}{0.5\\textwidth}\n",
      "                        \\includegraphics[width=\\textwidth]{\"\"\" + fig1 + r\"\"\"}\n",
      "                        \\caption{Normal scale}\n",
      "                \\end{subfigure}\\begin{subfigure}{0.5\\textwidth}\n",
      "                        \\includegraphics[width=\\textwidth]{\"\"\" + fig2 + r\"\"\"}\n",
      "                        \\caption{Log scale}\n",
      "                \\end{subfigure}\n",
      "            \\end{figure}\n",
      "            \\end{preview}\n",
      "            \\end{document}\n",
      "        \"\"\")\n",
      "        f.close()\n",
      "        subprocess.call([\"pdflatex\", \n",
      "                            \"-halt-on-error\", \n",
      "                            \"tmp.tex\"],\n",
      "                        cwd = self.tmp_directory)\n",
      "        shutil.move(os.path.join(self.tmp_directory, \"tmp.pdf\"), figure_path)\n",
      "\n",
      "    #Generate histograms of patient score record start times that are \n",
      "    #less than pain_data.start_recording_time_minutes_cutoff (normal and log scale)\n",
      "    def generate_cutoff_start_time_figures(self):\n",
      "        start_recording_time_minutes_cutoff = get_opt_val(\"pain_data.start_recording_time_minutes_cutoff\")\n",
      "        figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.start_times_lte_cutoff\"))\n",
      "        print(\"Generating histograms for record start times which are less than the cutoff, %s, and saving to %s\" %\n",
      "              (start_recording_time_minutes_cutoff, figure_path))\n",
      "        recording_time_grouped_by_patient = self.all_pain_data[[\"PatientID\", \"NRSTimeFromEndSurgery_mins\"]].groupby(\"PatientID\")\n",
      "        recording_start_minutes = recording_time_grouped_by_patient.min()\n",
      "        recording_start_cutoff_patientid_minutes = recording_start_minutes[recording_start_minutes <= start_recording_time_minutes_cutoff].dropna()\n",
      "\n",
      "        fig1 = \"fig1.pdf\"\n",
      "        fig2 = \"fig2.pdf\"\n",
      "\n",
      "        plt.figure(figsize=[8,4])\n",
      "        plt.title(\"Pain score recording start times less than \" + str(start_recording_time_minutes_cutoff) + \"\\nminutes postoperation\", fontsize=14).set_y(1.05) \n",
      "        plt.ylabel(\"Occurrences\", fontsize=14)\n",
      "        plt.xlabel(\"Recording Start Time (minutes)\", fontsize=14)\n",
      "        plt.hist(recording_start_cutoff_patientid_minutes.values, color=\"0.5\")\n",
      "        plt.savefig(os.path.join(self.tmp_directory, fig1), bbox_inches=\"tight\")\n",
      "        plt.close()\n",
      "        \n",
      "        plt.figure(figsize=[8,4])\n",
      "        plt.title(\"Pain score recording start times less than \" + str(start_recording_time_minutes_cutoff) + \"\\nminutes postoperation, log scale\", fontsize=14).set_y(1.05) \n",
      "        plt.ylabel(\"Occurrences\", fontsize=14)\n",
      "        plt.xlabel(\"Recording Start Time (minutes)\", fontsize=14)\n",
      "        plt.hist(recording_start_cutoff_patientid_minutes.values, log=True, color=\"0.5\")\n",
      "        plt.savefig(os.path.join(self.tmp_directory, fig2), bbox_inches=\"tight\")\n",
      "        plt.close()\n",
      "        \n",
      "        cutoff_patientids = recording_start_cutoff_patientid_minutes.index\n",
      "        start_cutoff_pain_data = self.all_pain_data.set_index(\"PatientID\").ix[cutoff_patientids].reset_index()\n",
      "\n",
      "        #save the figures in panel format\n",
      "\n",
      "        f = open(os.path.join(self.tmp_directory, \"tmp.tex\"), 'w')\n",
      "        f.write(r\"\"\"\n",
      "            \\documentclass[%\n",
      "            ,float=false % this is the new default and can be left away.\n",
      "            ,preview=true\n",
      "            ,class=scrartcl\n",
      "            ,fontsize=20pt\n",
      "            ]{standalone}\n",
      "            \\usepackage[active,tightpage]{preview}\n",
      "            \\usepackage{varwidth}\n",
      "            \\usepackage{graphicx}\n",
      "            \\usepackage[justification=centering]{caption}\n",
      "            \\usepackage{subcaption}\n",
      "            \\usepackage[caption=false,font=footnotesize]{subfig}\n",
      "            \\renewcommand{\\thesubfigure}{\\Alph{subfigure}}\n",
      "            \\begin{document}\n",
      "            \\begin{preview}\n",
      "            \\begin{figure}[h]\n",
      "                \\begin{subfigure}{0.5\\textwidth}\n",
      "                        \\includegraphics[width=\\textwidth]{\"\"\" + fig1 + r\"\"\"}\n",
      "                        \\caption{Normal scale}\n",
      "                \\end{subfigure}\\begin{subfigure}{0.5\\textwidth}\n",
      "                        \\includegraphics[width=\\textwidth]{\"\"\" + fig2 + r\"\"\"}\n",
      "                        \\caption{Log scale}\n",
      "                \\end{subfigure}\n",
      "            \\end{figure}\n",
      "            \\end{preview}\n",
      "            \\end{document}\n",
      "        \"\"\")\n",
      "        f.close()\n",
      "        subprocess.call([\"pdflatex\", \n",
      "                            \"-halt-on-error\", \n",
      "                            \"tmp.tex\"],\n",
      "                        cwd = self.tmp_directory)\n",
      "        shutil.move(os.path.join(self.tmp_directory, \"tmp.pdf\"), figure_path)\n",
      "        return start_cutoff_pain_data\n",
      "    \n",
      "    def pain_score_histogram(self):\n",
      "        figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.raw_scores_histogram\"))\n",
      "        print(\"Generating pain score histogram and saving to \" + figure_path)\n",
      "        fig = plt.figure(figsize=(7,4))\n",
      "        self.pain_data_start_cutoff.reset_index().PainScoreQuantMissing.hist(bins=11, color=\"0.5\")\n",
      "        plt.xlabel(\"Reported pain score\")\n",
      "        plt.ylabel(\"Occurences\")\n",
      "        plt.title(\"Occurences of reported pain scores in data file\", y=1.03)\n",
      "        plt.gcf().subplots_adjust(bottom=0.15)\n",
      "        plt.savefig(figure_path)\n",
      "        plt.close()\n",
      "     \n",
      "    def gen_table1(self):\n",
      "        table1_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.table1_out_path\"))\n",
      "        print(\"Generating table1 and saving to \" + table1_path)\n",
      "        \n",
      "        interpolated_by_patient = self.driver.ts_df_interpolated.reset_index().set_index(\"PatientID\")\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", \"Gender\", \"Age_Group\"]].drop_duplicates()\n",
      "        counts = patients_with_key.groupby([\"Gender\", \"Age_Group\"]).count()[\"PatientID\"]\n",
      "        table1 = pd.DataFrame(columns=[\"Variable\", \"Level1\", \"Level2\", \"Value\", \"Average Pain Score\"]).set_index([\"Variable\", \"Level1\", \"Level2\"])\n",
      "\n",
      "        def comma(integer):\n",
      "            return \"{:,}\".format(integer)\n",
      "\n",
      "        def pct(count, total):\n",
      "            return str(round(100 * float(count) / total, 1))\n",
      "\n",
      "        def truncflt(flt):\n",
      "            return \"%.2f\" % flt\n",
      "        \n",
      "        total_patients = self.all_pain_data.PatientID.drop_duplicates().count()\n",
      "        print(\"Number of patients\", comma(total_patients))\n",
      "\n",
      "        total_nonsleep_pain_scores = self.all_pain_data.PainScoreQuantMissing.dropna().count()\n",
      "        print(\"Total nonsleep pain scores - \", comma(total_nonsleep_pain_scores))\n",
      "\n",
      "        patients_before_2_hours = self.driver.ts_df.PatientID.drop_duplicates()\n",
      "        print(\"Patients with scores before 2 hours - \", comma(patients_before_2_hours.count()))\n",
      "\n",
      "        pain_scores_for_patients_before_2_hours = self.driver.ts_df.PainScoreQuantMissing.dropna().count()\n",
      "        print(\"Scores for patients scores before 2 hours - \", comma(pain_scores_for_patients_before_2_hours))\n",
      "\n",
      "        interpolated_pain_scores = self.driver.ts_df_interpolated.PainScoreQuantMissing.dropna().count()\n",
      "        print(\"Interpolated scores - \", comma(interpolated_pain_scores))\n",
      "\n",
      "\n",
      "        #-------- Age group -------------\n",
      "        key = \"Age_Group\"\n",
      "        variable = \"Age\"\n",
      "        patient_with_age = self.driver.ts_df[[\"PatientID\", \"Age\"]].drop_duplicates()\n",
      "        age_mean = patient_with_age.Age.mean().round(1)\n",
      "        age_stddev = patient_with_age.Age.std().round(1)\n",
      "\n",
      "        table1.loc[(variable, \"\", \"\"), \"Value\"] = str(age_mean) + \"+/-\" + str(age_stddev) + r\" (mean +/- SD)\"\n",
      "        table1.loc[(variable, \"\", \"\"), \"Average Pain Score\"] = \"\"\n",
      "\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", key]].drop_duplicates()\n",
      "        level_counts = patients_with_key.groupby(key).count()[\"PatientID\"]\n",
      "        for level, count in level_counts.to_dict().iteritems():\n",
      "            table1.loc[(variable, level, \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, level_counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[patients_with_key[key] == level].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, level, \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- Age group coclustered with opioid -------------\n",
      "        variable = \"Age co-clustered with Opioid\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", \"Age_Group\", \"Opioid\"]].drop_duplicates()\n",
      "        counts = patients_with_key.groupby([\"Age_Group\", \"Opioid\"]).count()[\"PatientID\"]\n",
      "        for levels, count in counts.to_dict().iteritems():\n",
      "            age_group = levels[0]\n",
      "            opioid = (\"Taking\" if levels[1] else \"Not taking\") + \" Opioid\"\n",
      "            table1.loc[(variable, age_group, opioid), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[(patients_with_key.Age_Group == age_group) & (patients_with_key.Opioid == levels[1])].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, age_group, opioid), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- Gender -------------\n",
      "        variable = \"Gender\"\n",
      "        key = \"Gender\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", key]].drop_duplicates()\n",
      "        level_counts = patients_with_key.groupby(key).count()[\"PatientID\"]\n",
      "        for level, count in level_counts.to_dict().iteritems():\n",
      "            table1.loc[(variable, level, \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, level_counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[patients_with_key[key] == level].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, level, \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- Gender co-clustered with age group -------------\n",
      "        variable = \"Gender co-clustered with Age\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", \"Gender\", \"Age_Group\"]].drop_duplicates()\n",
      "        counts = patients_with_key.groupby([\"Gender\", \"Age_Group\"]).count()[\"PatientID\"]\n",
      "        for levels, count in counts.to_dict().iteritems():\n",
      "            gender = levels[0]\n",
      "            age_group = levels[1]\n",
      "            table1.loc[(variable, gender, age_group), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[(patients_with_key.Gender == gender) & (patients_with_key.Age_Group == age_group)].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, gender, age_group), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- Gender co-clustered with SSRI -------------\n",
      "        variable = \"Gender co-clustered with SSRI\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", \"Gender\", \"SSRI\"]].drop_duplicates()\n",
      "        counts = patients_with_key.groupby([\"Gender\", \"SSRI\"]).count()[\"PatientID\"]\n",
      "        count = counts.ix[\"FEMALE\", True]\n",
      "        table1.loc[(variable, \"Female\", \"Taking SSRI\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"FEMALE\") & (patients_with_key.SSRI == True)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Female\", \"Taking SSRI\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[\"MALE\", True]\n",
      "        table1.loc[(variable, \"Male\", \"Taking SSRI\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"MALE\") & (patients_with_key.SSRI == True)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Male\", \"Taking SSRI\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[\"FEMALE\", False]\n",
      "        table1.loc[(variable, \"Female\", \"Not taking SSRI\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"FEMALE\") & (patients_with_key.SSRI == False)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Female\", \"Not taking SSRI\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[\"MALE\", False]\n",
      "        table1.loc[(variable, \"Male\", \"Not taking SSRI\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"MALE\") & (patients_with_key.SSRI == False)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Male\", \"Not taking SSRI\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "\n",
      "        #-------- Gender co-clustered with Opioid -------------\n",
      "        variable = \"Gender co-clustered with Opioid\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", \"Gender\", \"Opioid\"]].drop_duplicates()\n",
      "        counts = patients_with_key.groupby([\"Gender\", \"Opioid\"]).count()[\"PatientID\"]\n",
      "        count = counts.ix[\"FEMALE\", True]\n",
      "        table1.loc[(variable, \"Female\", \"Taking Opioid\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"FEMALE\") & (patients_with_key.Opioid == True)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Female\", \"Taking Opioid\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[\"MALE\", True]\n",
      "        table1.loc[(variable, \"Male\", \"Taking Opioid\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"MALE\") & (patients_with_key.Opioid == True)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Male\", \"Taking Opioid\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[\"FEMALE\", False]\n",
      "        table1.loc[(variable, \"Female\", \"Not taking Opioid\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"FEMALE\") & (patients_with_key.Opioid == False)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Female\", \"Not taking Opioid\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[\"MALE\", False]\n",
      "        table1.loc[(variable, \"Male\", \"Not taking Opioid\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[(patients_with_key.Gender == \"MALE\") & (patients_with_key.Opioid == False)].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Male\", \"Not taking Opioid\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- Opioid -------------\n",
      "        variable = \"Opioid\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", \"Opioid\"]].drop_duplicates()\n",
      "        counts = patients_with_key.groupby([\"Opioid\"]).count()[\"PatientID\"]\n",
      "        count = counts.ix[True]\n",
      "        table1.loc[(variable, \"Taking Opioid\", \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[patients_with_key.Opioid == True].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Taking Opioid\", \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        count = counts.ix[False]\n",
      "        table1.loc[(variable, \"Not taking Opioid\", \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, counts.sum()) + \"%)\"\n",
      "        patients_in_cluster = patients_with_key[patients_with_key.Opioid == False].PatientID.values\n",
      "        pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "        pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "        table1.loc[(variable, \"Not taking Opioid\", \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- surgery type -------------\n",
      "        variable = \"CPT anatomic groupings\"\n",
      "        key = \"PrimaryCPTCodeCategory2\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", key]].drop_duplicates()\n",
      "        level_counts = patients_with_key.groupby(key).count()[\"PatientID\"]\n",
      "        for level, count in level_counts.to_dict().iteritems():\n",
      "            table1.loc[(variable, level, \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, level_counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[patients_with_key[key] == level].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, level, \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #variable = \"Time of observation\"\n",
      "        #t1(variable)     \n",
      "        #patient_max_recording_days = self.driver.ts_df[[\"PatientID\", \"NRSTimeFromEndSurgery_mins\"]]\\\n",
      "        #                            .groupby(\"PatientID\")\\\n",
      "        #                            .max() // (60*24) \n",
      "        #for day in range(0, 5):\n",
      "        #    count = patient_max_recording_days[patient_max_recording_days >= day].count()\n",
      "        #    t1(variable, \"POD\" + str(day + 1), comma(count) + \" (\" + pct(count) + \"%)\")\n",
      "\n",
      "        #-------- comobidities -------------\n",
      "        variable = \"Total number of ICD9 coded comorbidities\"\n",
      "        key = \"ICD9_Comorbidity_Count_Group\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", key]].drop_duplicates()\n",
      "        level_counts = patients_with_key.groupby(key).count()[\"PatientID\"]\n",
      "        for level, count in level_counts.to_dict().iteritems():\n",
      "            table1.loc[(variable, level, \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, level_counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[patients_with_key[key] == level].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, level, \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        #-------- Procedure count -------------\n",
      "        variable = \"Total number of CPT coded procedures\"\n",
      "        key = \"Total_CPT_Count_Group\"\n",
      "        patients_with_key = self.driver.ts_df[[\"PatientID\", key]].drop_duplicates()\n",
      "        level_counts = patients_with_key.groupby(key).count()[\"PatientID\"]\n",
      "        for level, count in level_counts.to_dict().iteritems():\n",
      "            table1.loc[(variable, level, \"\"), \"Value\"] = comma(count) + \" (\" + pct(count, level_counts.sum()) + \"%)\"\n",
      "            patients_in_cluster = patients_with_key[patients_with_key[key] == level].PatientID.values\n",
      "            pain_avg = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.mean()\n",
      "            pain_sd = interpolated_by_patient.ix[patients_in_cluster].PainScoreQuantMissing.std()\n",
      "            table1.loc[(variable, level, \"\"), \"Average Pain Score\"] = truncflt(pain_avg) + \"+/-\" + truncflt(pain_sd)\n",
      "\n",
      "        table1.to_csv(\"/tmp/table1.csv\")\n",
      "        \n",
      "    def demonstrate_interpolation_procedure(self):\n",
      "        interp_figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.interpolation_demo.interpolation\"))\n",
      "        paa_figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.interpolation_demo.paa\"))\n",
      "        sax_figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.interpolation_demo.sax\"))\n",
      "        sample_data = [\n",
      "            [1, 3, 6],\n",
      "            [1, 24, 8],\n",
      "            [1, 55, 9],\n",
      "            [1, 78, 5],\n",
      "            [1, 115, 4],\n",
      "            [1, 135, 1],\n",
      "            [1, 160, 2],\n",
      "            [1, 194, 1],\n",
      "            [1, 215, 6],\n",
      "            [1, 255, 9]\n",
      "        ]\n",
      "        sample_data_df = pd.DataFrame.from_records(sample_data, \n",
      "                                                   columns = [\"PatientID\", \n",
      "                                                              \"NRSTimeFromEndSurgery_mins\", \n",
      "                                                              \"PainScoreQuantMissing\"]\n",
      "                                                   )\n",
      "        tmp_driver = Driver(sample_data_df, lambda r: \"dummy\")\n",
      "        tmp_driver.interpolate_timeseries()\n",
      "\n",
      "        fig = plt.figure(figsize=(7, 4))\n",
      "        ax = fig.add_axes([0.15, 0.1, 0.78, 0.8])\n",
      "        plt.hold(True)\n",
      "        \n",
      "        print(\"Generating interpolation demonstration figure and saving to \" + interp_figure_path)\n",
      "        print(\"Sample input values:\")\n",
      "        print(\", \".join(sample_data_df.apply(lambda row: 'Minute ' + str(row.NRSTimeFromEndSurgery_mins) + \": \" + (\"%1.1f\" % (row.PainScoreQuantMissing)), axis=1).values))\n",
      "        print(\"Interpolated values:\")\n",
      "        print(\", \".join(tmp_driver.ts_df_interpolated.reset_index().apply(lambda row: 'Minute ' + str(row.level_1) + \": \" + (\"%1.1f\" % (row.PainScoreQuantMissing)), axis=1).values))\n",
      "        constant_time_interval_points = np.arange(sample_data_df.NRSTimeFromEndSurgery_mins.min(), \n",
      "                                                  sample_data_df.NRSTimeFromEndSurgery_mins.max(), \n",
      "                                                  get_opt_val(\"driver.time_series.interpolation_interval\"))\n",
      "        all_relevant_points = np.union1d(sample_data_df.NRSTimeFromEndSurgery_mins, constant_time_interval_points)\n",
      "        p1, = ax.plot(pd.Series(sample_data_df.NRSTimeFromEndSurgery_mins) - sample_data_df.NRSTimeFromEndSurgery_mins[0], \n",
      "                      sample_data_df.PainScoreQuantMissing.values,\n",
      "                      'ko', \n",
      "                      figure = fig, \n",
      "                      label = 'Recorded')\n",
      "        p2, = ax.plot(constant_time_interval_points - sample_data_df.NRSTimeFromEndSurgery_mins[0], \n",
      "                      tmp_driver.ts_df_interpolated.values, \n",
      "                      \"kx\", \n",
      "                      figure = fig, \n",
      "                      label = 'Interpolated')\n",
      "        interp_func = interp1d(sample_data_df.NRSTimeFromEndSurgery_mins, sample_data_df.PainScoreQuantMissing)\n",
      "        p3, = ax.plot(all_relevant_points - sample_data_df.NRSTimeFromEndSurgery_mins[0], \n",
      "                      interp_func(all_relevant_points), \n",
      "                      \"k:\", \n",
      "                      figure = fig, \n",
      "                      label = 'interpolation_line')\n",
      "        p4, = ax.plot([], [], \"k-\", figure=fig, label='paa_lines')\n",
      "        p5, = ax.plot([], [], \"k--\", figure=fig, label='sax_lines')\n",
      "        ax.legend([p1, p2], [\"Recorded\", \"Interpolated\"], loc='upper center', fontsize=12)\n",
      "        ax.set_ylim(0, 10)\n",
      "        ax.set_xlim(0, 260)\n",
      "        ax.set_title(\"Sample Pain Scores\", fontsize=18, y=1.03)\n",
      "        ax.set_xlabel(\"$t$\", fontsize=18)\n",
      "        ax.set_ylabel(\"$pain\\ score$\", fontsize=18)\n",
      "        fig.savefig(interp_figure_path, bbox_inches=\"tight\")\n",
      "\n",
      "        print(\"Generating PAA demonstration figure and saving to \" + paa_figure_path)\n",
      "        paa_vals = tmp_driver.piecewise_aggregate_approximation(tmp_driver.ts_df_interpolated.PainScoreQuantMissing, 5)\n",
      "        ax.hlines(paa_vals[0], 0, 50, linewidth=2)\n",
      "        ax.hlines(paa_vals[1], 50, 100, linewidth=2)\n",
      "        ax.hlines(paa_vals[2], 100, 150, linewidth=2)\n",
      "        ax.hlines(paa_vals[3], 150, 200, linewidth=2)\n",
      "        ax.hlines(paa_vals[4], 200, 250, linewidth=2)\n",
      "        ax.legend([p1, p2, p4], [\"Recorded\", \"Interpolated\", \"PAA\"], loc='upper center', fontsize=12)\n",
      "        fig.savefig(paa_figure_path, bbox_inches=\"tight\")\n",
      "        print(\"PAA=\" + str(paa_vals.values))\n",
      "\n",
      "        print(\"Generating SAX demonstration figure and saving to \" + sax_figure_path)\n",
      "        #the following are quantile breakpoints generated from the pain data set\n",
      "        beta_3_breakpoints = [0.0, 2.0, 5.09, inf]\n",
      "        ax.hlines(beta_3_breakpoints[1], 0, 260, linewidth=1, linestyles=\"--\")\n",
      "        ax.hlines(beta_3_breakpoints[2], 0, 260, linewidth=1, linestyles=\"--\")\n",
      "        ax.text(-0.17, (beta_3_breakpoints[2] + 10) / 20 - 0.03, \"c\", transform=ax.transAxes, fontsize=24,\n",
      "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'), zorder=100)\n",
      "        ax.text(-0.17, (beta_3_breakpoints[1] + beta_3_breakpoints[2]) / 20 - 0.03, \"b\", transform=ax.transAxes, fontsize=24,\n",
      "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'), zorder=100)\n",
      "        ax.text(-0.17, beta_3_breakpoints[1] / 20 - 0.03, \"a\", transform=ax.transAxes, fontsize=24,\n",
      "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'), zorder=100)\n",
      "        #hack to avoid cliping the left margin\n",
      "        ax.text(-0.2, (1./3. / 2) - 0.03, \"a\", transform=ax.transAxes, color=\"white\", zorder=1)\n",
      "        ax.legend([p1, p2, p4, p5], [\"Recorded\", \"Interpolated\", \"PAA\", \"Breakpoint\"], loc='upper center', fontsize=12)\n",
      "        fig.savefig(sax_figure_path, bbox_inches=\"tight\")\n",
      "        plt.hold(False)\n",
      "        plt.close(fig)\n",
      "        \n",
      "    def demonstrate_paa_frame_length_determination(self):\n",
      "        figure_path = os.path.join(self.output_directory, get_opt_val(\"pain_data.figures.paa_frame_length_demo\"))\n",
      "        print(\"Generating figure demonstrating PAA frame length calculation and saving to \" + figure_path)\n",
      "        datapoint_counts = self.driver.ts_df_interpolated \\\n",
      "                    .reset_index()[[\"PatientID\", \"NRSTimeFromEndSurgery_mins\"]] \\\n",
      "                    .set_index(\"PatientID\") \\\n",
      "                    .groupby(level=0) \\\n",
      "                    .count()\n",
      "        datapoint_counts.columns = [\"number_of_points\"]\n",
      "        short_recovery_patients = datapoint_counts[datapoint_counts.number_of_points <= 30].index.values\n",
      "        datapoint_counts.drop(short_recovery_patients, inplace=True)\n",
      "        d = datapoint_counts.number_of_points - 1\n",
      "        w = np.ceil(d / 30.)\n",
      "        window_length = d / w  * 10. / 60.\n",
      "\n",
      "        fig = plt.figure(figsize = (10, 4))\n",
      "        plt.plot(datapoint_counts.values, window_length.values, 'k.')\n",
      "        plt.ylabel(\"Observed frame duration (hours)\", fontsize = 14)\n",
      "        plt.xlabel(\"$d$\", fontsize = 18)\n",
      "        plt.title(\"Observed PAA frame duration versus interpolated score dimensions\", fontsize = 14, y = 1.03) \n",
      "        plt.ylim((0, 5))\n",
      "        plt.savefig(figure_path, bbox_inches=\"tight\")\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    }
   ],
   "metadata": {}
  }
 ]
}